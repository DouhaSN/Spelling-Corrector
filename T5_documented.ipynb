{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets"
      ],
      "metadata": {
        "id": "3DTLSEdLNs-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description : Cette ligne de code utilise la commande pip pour installer les bibliothèques transformers et datasets. Ces bibliothèques sont des outils essentiels pour travailler avec des modèles de Transformers pré-entraînés et des ensembles de données dans le domaine du Traitement Automatique du Langage Naturel (NLP)."
      ],
      "metadata": {
        "id": "4FXh6g46N0mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pytorch-lightning wandb"
      ],
      "metadata": {
        "id": "c0uguxjWNs3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description : Cette ligne de code utilise la commande pip pour installer silencieusement les bibliothèques pytorch-lightning et wandb. Ces bibliothèques sont utilisées pour faciliter l'entraînement de modèles PyTorch et pour effectuer un suivi et une visualisation avancés des expériences d'entraînement."
      ],
      "metadata": {
        "id": "jU1tiy-lN31c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rlp5dGUiNSm2"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries and modules\n",
        "\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSeq2SeqLM, get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from tqdm import tnrange\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# from evaluate import load\n",
        "# import bert_score\n",
        "from transformers import logging\n",
        "logging.set_verbosity_error()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
        "\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description :\n",
        "Ce code commence par importer les bibliothèques et modules nécessaires pour le projet. Ces bibliothèques incluent des outils pour la gestion des données, la création de modèles, l'entraînement, la visualisation, et plus encore. La désactivation de la parallélisation des tokenizers est également effectuée pour améliorer les performances."
      ],
      "metadata": {
        "id": "2LSOQodRPjpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La configuration `os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"` a pour but de désactiver la parallélisation des tokenizers dans la bibliothèque Transformers. Par défaut, Transformers essaie d'accélérer le prétraitement des données en parallélisant les opérations de tokenization sur plusieurs cœurs de processeur (si disponibles). Cela peut être utile pour accélérer le traitement des données, en particulier lorsqu'il s'agit de grands jeux de données.\n",
        "\n",
        "Cependant, dans certains environnements ou configurations, la parallélisation automatique peut entraîner des problèmes, tels que des conflits de ressources ou des erreurs liées à la gestion des threads. Pour éviter ces problèmes, cette configuration désactive la parallélisation, ce qui peut ralentir légèrement le prétraitement des données, mais assure une exécution plus stable du code, en particulier sur des systèmes avec des contraintes de ressources."
      ],
      "metadata": {
        "id": "WUtpsj-cRqxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "\n",
        "dataset = load_dataset(\"Owishiboo/grammar-correction\", split=\"train\")\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "VAaUp9gSRwpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code charge un ensemble de données provenant du jeu de données \"Owishiboo/grammar-correction\" en utilisant la bibliothèque Hugging Face datasets. Plus précisément, il charge la partition d'entraînement (split=\"train\") de ce jeu de données."
      ],
      "metadata": {
        "id": "8pwhgjxfTxu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separation of the dataset into training, validation and test sets\n",
        "\n",
        "train_testvalid = dataset.train_test_split(test_size=0.2)\n",
        "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
        "\n",
        "dataset = DatasetDict({\n",
        "    'train': train_testvalid['train'],\n",
        "    'test': test_valid['test'],\n",
        "    'valid': test_valid['train']})\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "UjVWkCm8RxXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette séquence de code divise le dataset en trois parties distinctes : l'ensemble d'entraînement, l'ensemble de test et l'ensemble de validation. Cela garantit que nous disposons de données distinctes pour chaque phase de notre modèle de correction orthographique en NLP.\n",
        "\n",
        "80 % pour l'entraînement, 10 % pour le test et 10 % pour la validation.\n",
        "\n",
        "Nous organisons finalement nos données divisées dans une structure de type DatasetDict qui contient trois sous-ensembles : train, test et validation.\n"
      ],
      "metadata": {
        "id": "k9uS1F_AWHI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying a sample data example\n",
        "\n",
        "example = dataset['train'][0]\n",
        "\n",
        "print(\"input:\", example[\"input\"])\n",
        "print(\"target:\", example[\"target\"])"
      ],
      "metadata": {
        "id": "4bytlUxERxTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cela nous permet de visualiser un exemple spécifique que notre modèle de correction orthographique tentera de corriger pendant l'entraînement."
      ],
      "metadata": {
        "id": "Xmr0_fQGXkYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer Configuration and Preprocessing Function\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "prefix = \"correction: \"\n",
        "max_input_length = 600\n",
        "max_target_length = 600\n",
        "\n",
        "def preprocessor(examples, prefix='correction:', max_input_length=512, max_target_length=512):\n",
        "  sentences = examples['input']\n",
        "  corrections = examples['target']\n",
        "\n",
        "  # encode the input sentences\n",
        "  inputs = [prefix + sentence for sentence in sentences]\n",
        "  model_inputs = tokenizer(inputs, max_length=max_input_length, padding=\"max_length\", truncation=True)\n",
        "\n",
        "  # encode the target sentences and extract input_ids\n",
        "  labels = tokenizer(corrections, max_length=max_target_length, padding=\"max_length\", truncation=True).input_ids\n",
        "\n",
        "  # Replace the index of the padding tokens by -100\n",
        "  # such that they are not taken into account by the CrossEntropyLoss\n",
        "  labels_with_ignore_index = []\n",
        "  for labels_example in labels:\n",
        "    labels_example = [label if label != 0 else -100 for label in labels_example]\n",
        "    labels_with_ignore_index.append(labels_example)\n",
        "\n",
        "  model_inputs[\"labels\"] = labels_with_ignore_index\n",
        "\n",
        "  return model_inputs"
      ],
      "metadata": {
        "id": "n58_OzAhRxQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code configure le tokenizer pour le modèle T5-small et définit une fonction de prétraitement preprocessor qui prend des exemples d'entrée et de cible, ajoute un préfixe au texte d'entrée, les tokenise, gère les longueurs maximales, et formate les étiquettes avec des indices -100 pour ignorer les tokens de rembourrage lors du calcul de la perte. Cette fonction de prétraitement est utilisée pour formater les données d'entraînement du modèle."
      ],
      "metadata": {
        "id": "XDJ3zg_UbNlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Mapping\n",
        "\n",
        "# Apply the preprocessing function to the entire dataset in batches\n",
        "dataset = dataset.map(preprocessor, batched=True)\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "id": "sMvhd-EusIda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code prend le jeu de données initial et applique la fonction de prétraitement preprocessor à l'ensemble du jeu de données en traitant les données par lots. Ensuite, il affiche le jeu de données modifié, qui est maintenant formaté et prêt à être utilisé pour l'entraînement du modèle."
      ],
      "metadata": {
        "id": "0bbvUUa5zrCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\"input_ids\" (identifiants de tokens d'entrée) :**\n",
        "\n",
        "Il s'agit d'une liste (ou d'un tableau) d'identifiants numériques qui représentent chaque token (mot ou sous-mot) dans le texte d'entrée. Ces identifiants sont généralement des entiers qui correspondent à des indices dans un vocabulaire préalablement défini. Chaque mot ou sous-mot est converti en un identifiant unique. Cela permet au modèle de comprendre le texte d'entrée sous une forme numérique.\n",
        "\n",
        "**\"attention_mask\" (masque d'attention) :**\n",
        "\n",
        "Le masque d'attention est une autre liste (ou tableau) de valeurs binaires (0 ou 1) qui a la même longueur que les \"input_ids\". Il indique au modèle quels tokens sont importants pour la tâche à accomplir (1 pour les tokens pertinents, 0 pour les tokens non pertinents). Il est utilisé pour spécifier où le modèle doit porter son attention et où il peut ignorer certains tokens. Cela aide à gérer les séquences de longueur variable.\n",
        "\n",
        "**\"labels\" (étiquettes ou cibles) :**\n",
        "\n",
        "Les \"labels\" sont généralement utilisés dans des tâches d'apprentissage supervisé. Ils représentent la sortie attendue du modèle pour un exemple donné. Par exemple, dans une tâche de classification de texte, les \"labels\" indiqueraient la classe ou la catégorie à laquelle appartient l'exemple d'entrée. Le modèle apprend à faire des prédictions en se basant sur ces étiquettes lors de l'entraînement.\n",
        "\n",
        "Ces trois éléments sont essentiels pour préparer et alimenter des données dans un modèle NLP, car ils permettent de représenter le texte d'entrée, de guider l'attention du modèle et de spécifier les sorties attendues pour l'entraînement."
      ],
      "metadata": {
        "id": "Xy9kBp3E2O5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Formatting\n",
        "\n",
        "# Set the dataset format to \"torch\"\n",
        "dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "id": "VMPyo4k0sIbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code configure le format du jeu de données pour qu'il soit compatible avec PyTorch en spécifiant les colonnes à inclure. Cela signifie que le jeu de données est maintenant prêt à être utilisé avec des modèles PyTorch, car il est dans un format approprié pour l'entraînement et l'évaluation."
      ],
      "metadata": {
        "id": "2h8uZgMj0va-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loaders Configuration\n",
        "\n",
        "# Determine the number of CPU cores available.\n",
        "num_workers = os.cpu_count()\n",
        "\n",
        "# Create data loaders for training, validation, and testing datasets.\n",
        "train_dataloader = DataLoader(dataset['train'], shuffle=True, batch_size=8, num_workers=num_workers)\n",
        "valid_dataloader = DataLoader(dataset['valid'], batch_size=4, num_workers=num_workers)\n",
        "test_dataloader = DataLoader(dataset['test'], batch_size=4, num_workers=num_workers)\n"
      ],
      "metadata": {
        "id": "Ix0SyL_URxMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code configure les chargeurs de données pour les ensembles d'entraînement, de validation et de test. Il utilise le nombre de cœurs de CPU disponibles pour spécifier le nombre de travailleurs (num_workers) à utiliser lors du chargement des données, ce qui permet un chargement plus rapide. Les données d'entraînement sont mélangées (shuffle=True) pour améliorer la généralisation du modèle lors de l'entraînement."
      ],
      "metadata": {
        "id": "H801x8bx1TMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch a batch from the training data loader\n",
        "\n",
        "batch = next(iter(train_dataloader))\n",
        "print(batch.keys())\n"
      ],
      "metadata": {
        "id": "_h6kILUkRxJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code extrait un lot de données du chargeur de données d'entraînement (train_dataloader) en utilisant la fonction next(iter(train_dataloader)). Ensuite, il affiche les clés du lot (batch.keys()) pour montrer quelles sont les différentes composantes de données disponibles dans le lot, telles que les identifiants d'entrée (input_ids), les masques d'attention (attention_mask), et les étiquettes (labels). Ces composantes sont essentielles pour former le modèle et effectuer des calculs d'entraînement."
      ],
      "metadata": {
        "id": "FL6mFZae4wOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the input_ids of the first example in the batch.\n",
        "tokenizer.decode(batch['input_ids'][0])"
      ],
      "metadata": {
        "id": "V2e_qdP443he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the labels of the first example in the batch, filtering out -100 tokens\n",
        "labels = batch['labels'][0]\n",
        "tokenizer.decode([label for label in labels if label != -100])"
      ],
      "metadata": {
        "id": "O0F1Y4M043fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les étiquettes contiennent les identifiants des mots corrigés pour le premier exemple. Ensuite, il décode ces étiquettes en texte en utilisant le tokenizer. Cependant, il filtre les tokens ayant la valeur -100, car ce sont les tokens de rembourrage et ne sont pas nécessaires pour l'affichage du texte corrigé. Le texte décodé est ensuite imprimé pour afficher la correction orthographique du modèle pour cet exemple."
      ],
      "metadata": {
        "id": "U5TrTEbL56L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class T5(pl.LightningModule):\n",
        "    def __init__(self, lr=5e-5, num_train_epochs=15, warmup_steps=1000):\n",
        "        # Initializes the T5 model and sets up training-related attributes\n",
        "        super().__init__()\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "        self.train_losses=[]\n",
        "        self.validation_losses=[]\n",
        "        self.config=self.model.config\n",
        "\n",
        "        self.train_losses_epoch=[]\n",
        "        self.validation_losses_epoch=[]\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # Performs a forward pass through the T5 model\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "    def common_step(self, batch, batch_idx):\n",
        "        outputs = self(**batch)\n",
        "        loss = outputs.loss\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self.common_step(batch, batch_idx)\n",
        "        # logs metrics for each training_step,\n",
        "        # and the average across the epoch\n",
        "        self.log(\"training_loss\", loss)\n",
        "        self.train_losses.append(loss)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self.common_step(batch, batch_idx)\n",
        "        self.log(\"validation_loss\", loss, on_epoch=True)\n",
        "        self.validation_losses.append(loss)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        # Calculate average loss for the epoch and append to the list\n",
        "        avg_train_loss = sum(self.train_losses)/ len(self.train_losses)\n",
        "        self.train_losses_epoch.append(avg_train_loss.item())\n",
        "\n",
        "        # Reset epoch loss accumulator\n",
        "        self.train_losses = []\n",
        "\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        # Calculate average loss for the epoch and append to the list\n",
        "        avg_val_loss = sum(self.validation_losses) / len(self.validation_losses)\n",
        "        self.validation_losses_epoch.append(avg_val_loss.item())\n",
        "\n",
        "        # Reset epoch loss accumulator\n",
        "        self.validation_losses = []\n",
        "\n",
        "        # Reset epoch loss accumulator\n",
        "        self.test_losses = []\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # create optimizer\n",
        "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr)\n",
        "        # create learning rate scheduler\n",
        "        num_train_optimization_steps = self.hparams.num_train_epochs * len(train_dataloader)\n",
        "        lr_scheduler = {'scheduler': get_linear_schedule_with_warmup(optimizer,\n",
        "                                                    num_warmup_steps=self.hparams.warmup_steps,\n",
        "                                                    num_training_steps=num_train_optimization_steps),\n",
        "                        'name': 'learning_rate',\n",
        "                        'interval':'step',\n",
        "                        'frequency': 1}\n",
        "\n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
        "\n",
        "\n",
        "    def generate(self, input_ids, max_new_tokens=100, device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
        "        input_ids=input_ids.clone().detach().reshape((1,-1)).to(device)\n",
        "        return self.model.generate(input_ids, max_new_tokens=max_new_tokens)\n",
        "\n",
        "\n",
        "    def push_to_hub(self, model_name, organization):\n",
        "        # Save the model\n",
        "        self.model.push_to_hub(model_name, organization)\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return train_dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return valid_dataloader\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return test_dataloader"
      ],
      "metadata": {
        "id": "CoIV75bz43c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description : Cette classe T5 définit un modèle Lightning pour l'entraînement et l'évaluation d'un modèle T5-small pour la correction orthographique. Le modèle est configuré pour effectuer des étapes d'entraînement, de validation et de test, enregistrant les pertes et utilisant un planificateur de taux d'apprentissage. Elle offre également la possibilité de générer du texte et de pousser le modèle vers un référentiel de modèle (Hub)."
      ],
      "metadata": {
        "id": "hW4PmF3Z6h0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "lr = 5e-5\n",
        "num_train_epochs = 10\n",
        "warmup_steps = 1000\n",
        "patience = 2\n",
        "max_epochs = 10\n",
        "\n",
        "# for early stopping, see https://pytorch-lightning.readthedocs.io/en/1.0.0/early_stopping.html?highlight=early%20stopping\n",
        "# Early stopping callback - Stops training if validation loss doesn't improve for 'patience' epochs\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor='validation_loss',\n",
        "    patience=patience,\n",
        "    strict=False,\n",
        "    verbose=False,\n",
        "    mode='min'\n",
        ")\n",
        "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
        "# Model checkpoint callback - Saves the best model during training based on validation loss\n",
        "checkpoint_callback = ModelCheckpoint(dirpath='./', monitor='validation_loss', mode='min', save_top_k = 1)\n",
        "\n",
        "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
        "# Create a PyTorch Lightning Trainer instance with defined callbacks and max_epochs\n",
        "trainer = Trainer(accelerator=accelerator,\n",
        "                  callbacks=[early_stop_callback, lr_monitor, checkpoint_callback], max_epochs=max_epochs)\n",
        "\n",
        "# Create an instance of our T5 model with specified hyperparameters\n",
        "model = T5(lr=lr, num_train_epochs=num_train_epochs, warmup_steps=warmup_steps)\n",
        "# Train the model\n",
        "trainer.fit(model)\n",
        "tokenizer.save_pretrained(\"./\")\n",
        "checkpoint_path = checkpoint_callback.best_model_path"
      ],
      "metadata": {
        "id": "6YNAJTUz43a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code configure les hyperparamètres pour l'entraînement, définit les rappels pour l'arrêt anticipé, la surveillance du taux d'apprentissage et l'enregistrement du modèle, puis entraîne le modèle T5 à l'aide du formateur PyTorch Lightning. Il enregistre également les poids du tokenizer et récupère le chemin du meilleur point de contrôle du modèle."
      ],
      "metadata": {
        "id": "aHiV4yec_5Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the training and validation losses of the model\n",
        "\n",
        "train_losses=model.train_losses_epoch\n",
        "validation_losses=model.validation_losses_epoch\n"
      ],
      "metadata": {
        "id": "WtQzza9H43Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code récupère les pertes d'entraînement et de validation d'un modèle. Les pertes d'entraînement sont les pertes calculées lors de l'entraînement du modèle sur le jeu de données d'entraînement, tandis que les pertes de validation sont les pertes calculées lors de la validation du modèle sur un jeu de données de validation distinct. Ces pertes sont généralement utilisées pour évaluer les performances du modèle et surveiller son apprentissage au fil des époques."
      ],
      "metadata": {
        "id": "moQq8g-9AwGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loss on validation set before fine tuning: ', validation_losses[0])"
      ],
      "metadata": {
        "id": "gPTv__QB43TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the losses\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(validation_losses[1:], label='Validation Loss')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('T5: Losses over Epochs')\n",
        "\n",
        "# Adding legend\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig('losses_plot.png')\n",
        "# Displaying the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5TaY1D-PA0oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code génère un graphique représentant l'évolution des pertes (losses) d'un modèle T5 au fil des époques d'entraînement. Les pertes d'entraînement sont tracées en bleu, tandis que les pertes de validation sont tracées en orange (à l'exception de la première valeur, car elle peut être aberrante en raison de la phase d'initialisation). Ce graphique permet de visualiser comment les pertes du modèle changent à mesure qu'il s'entraîne et de surveiller son apprentissage. Le graphique est ensuite sauvegardé en tant qu'image sous le nom 'losses_plot.png'."
      ],
      "metadata": {
        "id": "oJTE1ysHBDWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_id = 9\n",
        "test_dataset = dataset['test']\n",
        "test_input = test_dataset['input'][data_id]\n",
        "test_input_ids = test_dataset[data_id]['input_ids']\n",
        "test_target = test_dataset['target'][data_id]\n",
        "test_attention_mask = test_dataset[data_id]['attention_mask']"
      ],
      "metadata": {
        "id": "F_4sepbxA0kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code permet de sélectionner un échantillon de données spécifique dans l'ensemble de données de test.\n",
        "Les informations  de cet echantillon seront utilisées pour évaluer le modèle sur cet échantillon spécifique."
      ],
      "metadata": {
        "id": "aMlh4yIPB2Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if a GPU is available, and setting the device accordingly\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Moving the model to the selected device (GPU or CPU)\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "Cgrk8z6VA0gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input sentence:\")\n",
        "print(test_input)"
      ],
      "metadata": {
        "id": "Xzx5ldZtA0eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"target:\")\n",
        "print(test_target)"
      ],
      "metadata": {
        "id": "t00pD3coCQrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating corrected text using the fine-tuned T5 model\n",
        "output_ids = model.generate(test_input_ids.reshape((1,-1)))\n",
        "\n",
        "# Decoding the generated output and removing special tokens\n",
        "corrected_sentence = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "xJG69C5VCQpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce code génère une phrase corrigée en utilisant le modèle T5 fine-tuné. Il prend l'ID d'entrée de la phrase test, le passe au modèle, récupère la sortie générée, puis décode cette sortie en une phrase corrigée en supprimant les jetons spéciaux ajoutés par le modèle. En fin de compte, corrected_sentence contient la phrase corrigée."
      ],
      "metadata": {
        "id": "LaFVtKzNC6mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Corrected sentence:\")\n",
        "print(corrected_sentence)"
      ],
      "metadata": {
        "id": "ZWnwLTbVCQm8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}