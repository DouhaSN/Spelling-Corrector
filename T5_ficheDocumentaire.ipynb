{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def preprocessor(examples, prefix='correction:', max_input_length=512, max_target_length=512):\n",
        "  \"\"\"\n",
        "    Preprocesses the examples by tokenizing and formatting them for the T5 model.\n",
        "\n",
        "    Args:\n",
        "        examples (dict): A dictionary containing input and target sentences.\n",
        "        prefix (str): The prefix to add to each input sentence.\n",
        "        max_input_length (int): Maximum length for input sentences.\n",
        "        max_target_length (int): Maximum length for target sentences.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing tokenized input sentences, tokenized target sentences with padding,\n",
        "              and labels with padding tokens replaced by -100.\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "k3oVl1lySHZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T5 Class Documentation\n",
        "\n",
        "## Overview\n",
        "The `T5` class is a PyTorch Lightning module designed for fine-tuning the Hugging Face Transformers' T5 (Text-to-Text Transfer Transformer) model on sequence-to-sequence language tasks. It provides an interface for training, validation, testing, and generating sequences using the T5 model.\n",
        "\n",
        "## Constructor\n",
        "```python\n",
        "def __init__(self, lr=5e-5, num_train_epochs=15, warmup_steps=1000):\n"
      ],
      "metadata": {
        "id": "z92-ee6MU3n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Methods\n",
        "forward(self, input_ids, attention_mask, labels=None) -> Dict[str, Tensor]\n",
        "•\tinput_ids (Tensor): Input token IDs.\n",
        "•\tattention_mask (Tensor): Attention mask tensor.\n",
        "•\tlabels (Tensor, optional): Target token IDs for the labels. Default is None.\n",
        "\n",
        "training_step(self, batch, batch_idx) -> Tensor\n",
        "•\tbatch (dict): Input batch.\n",
        "•\tbatch_idx (int): Batch index.\n",
        "\n",
        "validation_step(self, batch, batch_idx) -> Tensor\n",
        "•\tbatch (dict): Input batch.\n",
        "•\tbatch_idx (int): Batch index.\n",
        "\n",
        "on_train_epoch_end(self) -> None\n",
        "•\tCalled at the end of each training epoch.\n",
        "\n",
        "on_validation_epoch_end(self) -> None\n",
        "•\tCalled at the end of each validation epoch.\n",
        "\n",
        "configure_optimizers(self) -> Dict[str, Any]\n",
        "•\tConfigures the optimizer and learning rate scheduler.\n",
        "\n",
        "generate(self, input_ids, max_new_tokens=100, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')) -> List[Tensor]\n",
        "•\tinput_ids (Tensor): Input token IDs for generation.\n",
        "•\tmax_new_tokens (int, optional): Maximum number of new tokens to generate. Default is 100.\n",
        "•\tdevice (torch.device, optional): Device for generation. Default is 'cuda' if available, else 'cpu'.\n",
        "\n",
        "push_to_hub(self, model_name, organization) -> None\n",
        "•\tPushes the trained model to the Hugging Face Model Hub.\n",
        "\n",
        "train_dataloader(self) -> DataLoader\n",
        "•\tReturns the training data loader.\n",
        "\n",
        "val_dataloader(self) -> DataLoader\n",
        "•\tReturns the validation data loader.\n",
        "\n",
        "test_dataloader(self) -> DataLoader\n",
        "•\tReturns the test data loader.\n",
        "\n"
      ],
      "metadata": {
        "id": "L2RWpt-NFDyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class T5(pl.LightningModule):\n",
        "    def __init__(self, lr=5e-5, num_train_epochs=15, warmup_steps=1000):\n",
        "        \"\"\"\n",
        "        Initializes the T5 model and sets up training-related attributes.\n",
        "\n",
        "        Args:\n",
        "            lr (float): Learning rate for optimization.\n",
        "            num_train_epochs (int): Number of training epochs.\n",
        "            warmup_steps (int): Number of warm-up steps for learning rate scheduling.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        \"\"\"\n",
        "        Performs a forward pass through the T5 model.\n",
        "\n",
        "        Args:\n",
        "            input_ids (tensor): Input token IDs.\n",
        "            attention_mask (tensor): Attention mask.\n",
        "            labels (tensor): Target token IDs for supervised training.\n",
        "\n",
        "        Returns:\n",
        "            outputs (tensor): Model outputs.\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def common_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Common processing step for training and validation.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): A batch of data.\n",
        "            batch_idx (int): Batch index.\n",
        "\n",
        "        Returns:\n",
        "            loss (tensor): Loss value.\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Training step for the Lightning module.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): A batch of data.\n",
        "            batch_idx (int): Batch index.\n",
        "\n",
        "        Returns:\n",
        "            loss (tensor): Training loss.\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Validation step for the Lightning module.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): A batch of data.\n",
        "            batch_idx (int): Batch index.\n",
        "\n",
        "        Returns:\n",
        "            loss (tensor): Validation loss.\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        \"\"\"\n",
        "        Called at the end of each training epoch.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        \"\"\"\n",
        "        Called at the end of each validation epoch.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"\n",
        "        Configures the optimizer and learning rate scheduler.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            optimizer_and_scheduler (dict): Optimizer and scheduler configurations.\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def generate(self, input_ids, max_new_tokens=100, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
        "        \"\"\"\n",
        "        Generates text using the T5 model.\n",
        "\n",
        "        Args:\n",
        "            input_ids (tensor): Input token IDs.\n",
        "            max_new_tokens (int): Maximum number of tokens to generate.\n",
        "            device (torch.device): Device for generation (CPU or GPU).\n",
        "\n",
        "        Returns:\n",
        "            generated_text (tensor): Generated text.\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def push_to_hub(self, model_name, organization):\n",
        "        \"\"\"\n",
        "        Pushes the model to the Hugging Face Model Hub.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Name of the model.\n",
        "            organization (str): Organization for the model on the Hub.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"\n",
        "        Provides the training DataLoader.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            train_dataloader (DataLoader): DataLoader for training data.\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        \"\"\"\n",
        "        Provides the validation DataLoader.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            val_dataloader (DataLoader): DataLoader for validation data.\n",
        "        \"\"\"\n",
        "        # ...\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        \"\"\"\n",
        "        Provides the test DataLoader.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            test_dataloader (DataLoader): DataLoader for test data.\n",
        "        \"\"\"\n",
        "        # ...\n"
      ],
      "metadata": {
        "id": "VZW0gLRWTeCR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}